<div align="center">

# CNN + GRU [ELU] 수어 인식 모델

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=yellow)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15+-orange?logo=tensorflow&logoColor=white)](https://tensorflow.org)
[![Keras](https://img.shields.io/badge/Keras-3.0-purple?logo=keras&logoColor=white)](https://keras.io)
[![License](https://img.shields.io/badge/License-MIT-green?logo=github)](LICENSE)
[![Progress](https://img.shields.io/badge/Progress-30%25-yellow)](https://github.com/yourusername/cnn-gru-sign-language)

**졸업프로젝트: 시간적 연속성 기반 수어 동작 인식 시스템**  
프레임별 키포인트 시퀀스 데이터로 CNN + GRU[ELU] 모델 개발.  
AI Hub 데이터셋 + MediaPipe 키포인트 활용. [web:201]

</div>

---

## 📋 프로젝트 소개

수어 영상 학습은 **동작 인식(action recognition)** 문제입니다.  
데이터는 프레임별 키포인트 좌표의 시간 순서(시퀀스) 형태입니다.  

단순 2D CNN으로는 시간적 연속성을 무시할 수밖에 없습니다.  
그래서 **시간 패턴을 처리할 수 있는 모델**을 선택했습니다.

### 🎯 핵심 아키텍처
- **CNN**: 공간 특징 추출 (손 모양, 포즈 등). 각 프레임의 키포인트 배열에서 제스처 패턴을 학습합니다.  
- **GRU**: 시간적 패턴 학습 (동작 흐름, 제스처 연속성). 프레임 간 순차적 관계를 처리해 전체 동작을 이해합니다.  
- **ELU**: 활성화 함수. 그래디언트 소실을 완화해 음수 입력에서도 안정적 학습을 지원합니다. [web:201]

### 왜 CNN + GRU인가?
| 이유 | 설명 |
|------|------|
| **GRU 효율성** | LSTM보다 구조 단순. 학습 속도 빠르고 계산 자원 적게 듭니다. 장기 의존성도 유사하게 처리. [web:203] |
| **파라미터 절약** | 게이트 구조 2개(LSTM 3개). 메모리 사용량 낮아 소규모 데이터셋에 적합. |
| **3D CNN 한계 극복** | 3D CNN 정확도 87%지만, 동적 단어 수화(연속 문장)에 약함. [web:205] |
| **비시계열 모델 문제** | RandomForest 등은 시간 순서 관계를 파악하기 어려움. |
| **ELU 이점** | 그래디언트 소실 개선. 깊은 네트워크에서 안정적 학습. [web:201] |

**입력 형식 예시**: (batch, 30, 42, 2)  
- 30프레임 시퀀스.  
- 21개 손 키포인트 × X/Y 좌표 (MediaPipe 추출).  
전체 시퀀스는 시간 흐름을 반영합니다.

---

## 🛤️ 프로젝트 타임라인

프로젝트는 9월부터 2월까지 진행합니다.  
각 단계별 주요 작업을 아래 테이블로 정리했습니다.

| 기간          | 단계                  | 주요 작업 |
|---------------|-----------------------|-----------|
| **9월~10월 초** | 주제 및 모델 탐색 | - 시계열 분류기 연구.<br>- LSTM: 장기 의존성 강점, 하지만 계산 비용 높음.<br>- GRU: LSTM보다 단순·빠름, 유사 효과.<br>- Transformer: 대규모 데이터 우수, 소규모 과적합 위험.<br>- CNN-RNN: 공간 + 시계열 최적 조합. |
| **10월 중순**   | 모델 결정 및 공부 | - CNN+GRU[ELU] 설계.<br>- 데이터 특성 분석: 프레임 i 키포인트 × 시퀀스.<br>- 2D CNN 한계(시간 무시) 극복. |
| **10월 말~11월**| 데이터 준비 | - AI Hub 데이터셋 + MediaPipe 키포인트 추출.<br>- 증강: 왼손잡이 반전 등.<br>- 분할: 80% 훈련 / 10% 검증 / 10% 테스트 (홀드아웃). |
| **11월~12월**   | 모델 구현 및 학습 | - CNN 특징 + GRU 시퀀스 + ELU 적용.<br>- 크로스 엔트로피 손실 + 역전파.<br>- Early Stopping으로 과적합 방지. |
| **12월~1월**    | 평가 및 최적화 | - Accuracy, F1-Score, 혼동 행렬 분석.<br>- 화자 독립성 + 손 우세성 보완. |
| **1월~2월**     | 배포 및 응용 | - 실시간 번역 시스템.<br>- 음성/텍스트 변환 연계. |

### 현재 진행 상황
- **진행률**: 30% (모델 설계 완료, 데이터 전처리 시작).  
- **다음 목표**: 10월 말 프로토타입 학습.  
- **위험 요인**: 키포인트 품질, GPU 자원.  
데이터 증강과 홀드아웃으로 안정적 기반 마련 중입니다.

---

## 🔬 핵심 머신러닝 개념

### 1️⃣ 홀드아웃 검증
데이터를 3부분으로 나눠 모델을 평가합니다.  
- **80% 훈련**: 가중치 학습.  
- **10% 검증**: 성능 점검 + 하이퍼파라미터 튜닝.  
- **10% 테스트**: 최종 성능 측정.  

**장점**: 과적합 방지. 새로운 데이터 신뢰성 확보.  
수어처럼 데이터 제한적일 때 표준 방법입니다.

### 2️⃣ 역전파
가중치(W)와 편향(b)을 조정하는 학습 알고리즘입니다.  

**학습 과정**:  
1. **순전파**: 입력 → 예측 출력.  
2. **오차 계산**: 실제 vs 예측 (손실 함수).  
3. **미분 계산**: 체인 룰로 영향 분석.  
4. **업데이트**: \( W \leftarrow W - \eta \frac{\partial L}{\partial W} \) (η: 학습률).  

수어 다중 클래스에 크로스 엔트로피 손실 사용.  
반복으로 모델이 패턴을 학습합니다.

#### 크로스 엔트로피 손실
\[ L = -\frac{1}{N} \sum_{i=1}^N \sum_{j=1}^K y_{i,j} \log(\hat{y}_{i,j}) \]  

- \( N \): 데이터 개수 (평균 계산).  
- \( K \): 클래스 수 (e.g., 26 알파벳).  
- \( y_{i,j} \): 실제 레이블 (원-핫: 정답=1, 나머지=0).  
- \( \hat{y}_{i,j} \): 예측 확률 (소프트맥스, 0~1).  

**예시**: 정답 [0,1,0], 예측 [0.1,0.8,0.1] → 손실 작음.  
[0.9,0.05,0.05] → 손실 큼 (틀린 예측 페널티).  
학습률 η로 업데이트 크기 조절. Adam과 함께 사용 추천.

### 3️⃣ Early Stopping
검증 손실 개선 없으면 학습 중단. 과적합 방지.  

**설정 예시**:  
from keras.callbacks import EarlyStopping  
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)  

**학습 적용**:  
history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping])  

- monitor: val_loss 추적.  
- patience: 3 에포크 개선 없음 → 중단.  
- restore: 최고 가중치 복원.  

수어 데이터 제한 시 불필요 에포크 줄여 효율적입니다.

### 4️⃣ ELU 활성화 함수
ReLU 단점 보완. 비선형 변환.  

\[ f(x) = x \ (x \geq 0), \quad f(x) = \alpha(e^x - 1) \ (x < 0) \]  

#### ReLU vs ELU
| 특징 | ReLU | ELU |
|------|------|-----|
| **수식** | \( \max(0, x) \) | 위 수식 (음수 부드러움). |
| **양수** | x 그대로 (빠름). | x 그대로. |
| **음수** | 0 차단 (죽은 뉴런). | 음수 변환 (학습 지속). |
| **문제** | Dying ReLU (20-30% 뉴런 사망). | 그래디언트 소실 ↓. |
| **효과** | 초기 빠름, 깊이 약함. | 안정적 수렴. |

**죽은 뉴런**: ReLU 음수 지속 → 출력 0, 학습 멈춤.  
ELU: 음수도 약간 출력 → 뉴런 활성 유지.  
CNN+GRU에서 시간 의존성 학습 강화. [web:201]

### 5️⃣ 평가 지표
수어 클래스 불균형에 적합.  

| 지표 | 설명 | 수식 | 수어 예시 |
|------|------|------|-----------|
| **Accuracy** | 전체 맞은 비율. | \( \frac{TP+TN}{전체} \) | 100 동작 중 90개 맞음 → 90%. 희귀 동작 왜곡 가능. |
| **Precision** | 예측 True 중 실제 True. | \( \frac{TP}{TP+FP} \) | "A" 예측 100 중 실제 95 → 95%. 오분류 최소. |
| **Recall** | 실제 True 중 예측 True. | \( \frac{TP}{TP+FN} \) | 실제 A 100 중 80 예측 → 80%. 놓침 최소. |
| **F1-Score** | Precision/Recall 조화평균. | \( 2 \frac{P \times R}{P+R} \) | P=90%, R=80% → 84.6%. 균형 평가. |

**혼동 행렬**: 실제 vs 예측 테이블. 대각선 크면 정확 (오분류 적음).  
e.g., 26 알파벳 중 A-E 유사 혼동 패턴 식별 → 데이터 보강.

### 6️⃣ 서명자 의존성
새 수화자 데이터에서 정확도 변동. 원인: 손 우세성 (왼손잡이 10%).  

**영향**: 오른손 학습 → 왼손 정확도 10-15% ↓.  
**해결**: 증강 (왼손 반전). 효과: 76% → 87%. 화자 독립성 강화.

### 7️⃣ 절대 프레임 차이
움직임 감지. 두 프레임 픽셀 차이 절댓값.  

\[ D(t) = \sum_{i,j} |I_t(i,j) - I_{t-1}(i,j)| \]  

- 손 움직임 → 차이 ↑ (동작 파악).  
- 30프레임 시퀀스에 추가 → 움직임 벡터 생성.  
키포인트와 결합: CNN 입력 강화. 변화 추적 효과적.

**개념 요약**:  
- 역전파: 순전파 → 오차 → 체인 룰 업데이트 반복.  
- ELU vs ReLU: ELU 음수 부드러움 (지수 곡선).  
- 혼동 행렬: 대각선 90%+ → 정확 높음 (e.g., A 실제 100 중 92 A 예측).

---

## 📚 개발 커리큘럼

단계별 계획. 도구 포함.

| 단계 | 세부 내용 | 도구/기법 |
|------|-----------|-----------|
| **데이터 준비** | - AI Hub 데이터 (5,000+ 영상).<br>- MediaPipe 키포인트 (21 랜드마크, 신뢰도 0.5+).<br>- 증강: 반전/회전.<br>- 분할: 80/10/10 홀드아웃. | MediaPipe, OpenCV, NumPy. |
| **모델 구현** | - CNN 공간 + GRU 시간 + ELU.<br>- 크로스 엔트로피 + 역전파.<br>- Early Stopping. | TensorFlow/Keras, Adam. |
| **평가 분석** | - 지표: Acc/P/R/F1.<br>- 혼동 행렬 (대각선 강함).<br>- 화자/손 우세성.<br>- 프레임 차이 추가. | Scikit-learn, Matplotlib. |
| **최적화 배포** | - 튜닝 (Grid Search).<br>- Lite 변환 (모바일).<br>- 환경 테스트.<br>- 실시간 0.1초 목표. | TensorFlow Lite, Flask. |
| **응용** | - TTS 음성 변환.<br>- 자막 텍스트.<br>- 앱 확장 (학습 모드). | Streamlit, React Native. |

**모델 예시 (간략)**:  
def create_model(): ... (CNN TimeDistributed + GRU 128 + ELU + Softmax).  
fit(epochs=100, callbacks=EarlyStopping(patience=3)).  

**평가 예시**:  
confusion_matrix로 heatmap. 대각선 분석 (오분류 패턴).

---

## 🛠️ 기술 스택

| 카테고리 | 기술 | 버전 | 용도 |
|----------|------|------|------|
| 언어 | Python | 3.10+ | 개발 스크립팅. |
| 프레임워크 | TensorFlow | 2.15+ | 모델 빌드/학습. |
| API | Keras | 3.0 | 레이어 정의. |
| 키포인트 | MediaPipe | 0.10+ | 손 랜드마크. |
| 데이터 | NumPy/Pandas | 1.24+/2.0+ | 처리/분할. |
| 시각화 | Matplotlib/Seaborn | 3.7+/0.13+ | 곡선/히트맵. |
| 평가 | Scikit-learn | 1.3+ | 지표/행렬. |
| 환경 | Jupyter | 1.0+ | 실험. |
| 버전 | Git/GitHub | 최신 | 공유. |

## 📁 프로젝트 구조

